{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate sample for FID evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, json, tqdm, os, shutil, numpy as np\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "from modules.util import instantiate_from_config\n",
    "from models.diffusion.ddim import DDIMSampler\n",
    "from models.diffusion.plms import PLMSSampler\n",
    "\n",
    "from PIL import Image\n",
    "from einops import rearrange\n",
    "from torchvision.utils import make_grid\n",
    "import torch\n",
    "\n",
    "ROOT_PATH = \"/mnt/data1/bardella_data/gitRepos/Thesis/ldm_porting\"\n",
    "\n",
    "dataset_dir = \"/mnt/data1/bardella_data/gitRepos/Thesis/Datasets/wikiart\"\n",
    "dataset_subdivided_dir = \"/mnt/data1/bardella_data/gitRepos/Thesis/Datasets/wikiart_subdivided_256\"\n",
    "mapping_file = \"/mnt/data1/bardella_data/gitRepos/Thesis/Datasets/mapping.json\"\n",
    "\n",
    "\n",
    "# Load the label literal-discrete mapping\n",
    "with open(mapping_file, \"r\") as fin:\n",
    "    mapping = json.load(fin)\n",
    "    mapping_r = {v:k for k, v in mapping}\n",
    "\n",
    "# Load the dataset image path and labels\n",
    "with open(dataset_dir+\"/dataset.json\", \"r\") as fin:\n",
    "    dataset_info = json.load(fin)[\"labels\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset per color subdivision and metadata generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dataset Subdivision per color label\n",
    "# new_dataset_info = {\"labels\":[]}\n",
    "\n",
    "# if not os.path.exists(dataset_subdivided_dir):\n",
    "#     for data in tqdm.tqdm(dataset_info):\n",
    "#         img_dir, label = data\n",
    "\n",
    "#         img_name, mapped_label = img_dir.split(\"/\")[1], mapping_r[label]\n",
    "\n",
    "#         dest_dir = \"/\".join((dataset_subdivided_dir,f\"{mapped_label}\"))\n",
    "\n",
    "#         new_dataset_info[\"labels\"].append([\"/\".join((mapped_label, img_name)), label])\n",
    "\n",
    "#         if not os.path.exists(dest_dir):\n",
    "#             os.makedirs(dest_dir)\n",
    "#         shutil.copy(dataset_dir + f\"/{img_dir}\", dest_dir)\n",
    "        \n",
    "\n",
    "#     with open(dataset_subdivided_dir+\"/dataset.json\", \"w\") as fout:\n",
    "#         json.dump(new_dataset_info, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from albumentations.augmentations.geometric.resize import Resize\n",
    "\n",
    "if not os.path.exists(dataset_subdivided_dir):\n",
    "    new_dataset_info = {\"labels\":[]}\n",
    "\n",
    "    src_dir = dataset_dir\n",
    "    dest_dir = dataset_subdivided_dir\n",
    "    resize_transform = Resize(height=256, width=256,always_apply=True)\n",
    "\n",
    "    for image_path, numerical_label in tqdm(dataset_info[:None]):\n",
    "\n",
    "        image_name, letteral_label = image_path.split(\"/\")[-1], mapping_r[numerical_label]\n",
    "\n",
    "        image = cv2.imread(src_dir + f\"/{image_path}\")\n",
    "        image_cvt = resize_transform(image=image)[\"image\"]\n",
    "\n",
    "        new_dataset_info[\"labels\"].append([\"/\".join((letteral_label, image_name)), numerical_label])\n",
    "\n",
    "        if not os.path.exists(dest_dir + f\"/{letteral_label}\"):\n",
    "            os.makedirs(dest_dir + f\"/{letteral_label}\")\n",
    "        \n",
    "        cv2.imwrite(dest_dir + f\"/{letteral_label}/{image_name}\", image_cvt)\n",
    "\n",
    "    with open(dest_dir+\"/dataset.json\", \"w\") as fout:\n",
    "        json.dump(new_dataset_info, fout)\n",
    "else:\n",
    "    print(\"This subdivision already exist\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate New Samples from the LD model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pretrained LDM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /mnt/data1/bardella_data/gitRepos/Thesis/ldm_porting/model_checkpts/ldm/wikiart/epoch=299-step=69600.ckpt\n",
      "LatentDiffusion: Running in eps-prediction mode\n",
      "DiffusionWrapper has 394.98 M params.\n",
      "Keeping EMAs of 628.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Restored from /mnt/data1/bardella_data/gitRepos/Thesis/ldm_porting/pretrained_model/vq-f8/model.ckpt with 0 missing and 49 unexpected keys\n"
     ]
    }
   ],
   "source": [
    "def load_model_from_config(config, ckpt):\n",
    "    print(f\"Loading model from {ckpt}\")\n",
    "    pl_sd = torch.load(ckpt, map_location=\"cpu\")\n",
    "    sd = pl_sd[\"state_dict\"]\n",
    "    model = instantiate_from_config(config.model)\n",
    "    m, u = model.load_state_dict(sd, strict=False)\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "config = OmegaConf.load(ROOT_PATH + \"/configs/custom-ldm-cwa-vq-f8.yaml\")  \n",
    "sample_folder = ROOT_PATH + f\"/sample/ldm/wikiart\"\n",
    "\n",
    "vq_gan_pretrained_ckpt_path = ROOT_PATH + \"/pretrained_model/vq-f8/model.ckpt\"\n",
    "ldm_pretrained_ckpt_path = ROOT_PATH + \"/model_checkpts/ldm/wikiart/epoch=299-step=69600.ckpt\"\n",
    "config.model.params.first_stage_config.params[\"ckpt_path\"] = vq_gan_pretrained_ckpt_path\n",
    "\n",
    "model = load_model_from_config(config, ldm_pretrained_ckpt_path)\n",
    "# sampler = DDIMSampler(model)\n",
    "# sampler_type = \"DDIM\"\n",
    "sampler = PLMSSampler(model)\n",
    "sampler_type = \"PLMS\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate new Sample for a specific class. \n",
    "This operation is very time consuming and require a lot of memory.\n",
    "\n",
    "The problem is we can only take about 15 samples at a time and it takes a few minuts for each batch.\n",
    "\n",
    "To sample 10_000 with 200 denoising timesteps we need 11 hours"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import numpy\n",
    "\n",
    "def computeFidPytorch(truth_dataset, generated_dataset, device):\n",
    "\n",
    "    output = subprocess.run(['python', \n",
    "                            '-m', \n",
    "                            'pytorch_fid', \n",
    "                            truth_dataset, \n",
    "                            generated_dataset, \n",
    "                            \"--device\", \n",
    "                            device], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
    "    \n",
    "\n",
    "    return numpy.float32(output.split(\" \")[-1][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rendering 10000 examples of class 'bianco' in 75 steps and using s=2.00.\n",
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.84it/s]\n",
      "100%|██████████| 118/118 [00:14<00:00,  8.30it/s]\n",
      "100%|██████████| 20/20 [00:02<00:00,  7.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler: 100%|██████████| 77/77 [00:41<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for PLMS sampling is (15, 4, 32, 32)\n",
      "Running PLMS Sampling with 77 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PLMS Sampler:  82%|████████▏ | 63/77 [00:34<00:07,  1.83it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 58\u001b[0m\n\u001b[1;32m     55\u001b[0m xc \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(sub_batch_size\u001b[39m*\u001b[39m[\u001b[39mcls\u001b[39m])\n\u001b[1;32m     56\u001b[0m c \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mget_learned_conditioning({model\u001b[39m.\u001b[39mcond_stage_key: xc\u001b[39m.\u001b[39mto(model\u001b[39m.\u001b[39mdevice)})\n\u001b[0;32m---> 58\u001b[0m samples_ddim, _ \u001b[39m=\u001b[39m sampler\u001b[39m.\u001b[39;49msample(S\u001b[39m=\u001b[39;49mddim_step,\n\u001b[1;32m     59\u001b[0m                                 conditioning\u001b[39m=\u001b[39;49mc,\n\u001b[1;32m     60\u001b[0m                                 batch_size\u001b[39m=\u001b[39;49msub_batch_size,\n\u001b[1;32m     61\u001b[0m                                 shape\u001b[39m=\u001b[39;49m[\u001b[39m4\u001b[39;49m, \u001b[39m32\u001b[39;49m, \u001b[39m32\u001b[39;49m],\n\u001b[1;32m     62\u001b[0m                                 verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     63\u001b[0m                                 unconditional_guidance_scale\u001b[39m=\u001b[39;49mscale,\n\u001b[1;32m     64\u001b[0m                                 unconditional_conditioning\u001b[39m=\u001b[39;49muc, \n\u001b[1;32m     65\u001b[0m                                 eta\u001b[39m=\u001b[39;49mddim_eta)\n\u001b[1;32m     67\u001b[0m x_samples_ddim \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mdecode_first_stage(samples_ddim)\n\u001b[1;32m     68\u001b[0m x_samples_ddim \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mclamp((x_samples_ddim\u001b[39m+\u001b[39m\u001b[39m1.0\u001b[39m)\u001b[39m/\u001b[39m\u001b[39m2.0\u001b[39m, \u001b[39mmin\u001b[39m\u001b[39m=\u001b[39m\u001b[39m0.0\u001b[39m, \u001b[39mmax\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m)\u001b[39m.\u001b[39mcpu()\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.9/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/mnt/data1/bardella_data/gitRepos/Thesis/ldm_porting/models/diffusion/plms.py:97\u001b[0m, in \u001b[0;36mPLMSSampler.sample\u001b[0;34m(self, S, batch_size, shape, conditioning, callback, normals_sequence, img_callback, quantize_x0, eta, mask, x0, temperature, noise_dropout, score_corrector, corrector_kwargs, verbose, x_T, log_every_t, unconditional_guidance_scale, unconditional_conditioning, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m size \u001b[39m=\u001b[39m (batch_size, C, H, W)\n\u001b[1;32m     95\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mData shape for PLMS sampling is \u001b[39m\u001b[39m{\u001b[39;00msize\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 97\u001b[0m samples, intermediates \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mplms_sampling(conditioning, size,\n\u001b[1;32m     98\u001b[0m                                             callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m     99\u001b[0m                                             img_callback\u001b[39m=\u001b[39;49mimg_callback,\n\u001b[1;32m    100\u001b[0m                                             quantize_denoised\u001b[39m=\u001b[39;49mquantize_x0,\n\u001b[1;32m    101\u001b[0m                                             mask\u001b[39m=\u001b[39;49mmask, x0\u001b[39m=\u001b[39;49mx0,\n\u001b[1;32m    102\u001b[0m                                             ddim_use_original_steps\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    103\u001b[0m                                             noise_dropout\u001b[39m=\u001b[39;49mnoise_dropout,\n\u001b[1;32m    104\u001b[0m                                             temperature\u001b[39m=\u001b[39;49mtemperature,\n\u001b[1;32m    105\u001b[0m                                             score_corrector\u001b[39m=\u001b[39;49mscore_corrector,\n\u001b[1;32m    106\u001b[0m                                             corrector_kwargs\u001b[39m=\u001b[39;49mcorrector_kwargs,\n\u001b[1;32m    107\u001b[0m                                             x_T\u001b[39m=\u001b[39;49mx_T,\n\u001b[1;32m    108\u001b[0m                                             log_every_t\u001b[39m=\u001b[39;49mlog_every_t,\n\u001b[1;32m    109\u001b[0m                                             unconditional_guidance_scale\u001b[39m=\u001b[39;49munconditional_guidance_scale,\n\u001b[1;32m    110\u001b[0m                                             unconditional_conditioning\u001b[39m=\u001b[39;49munconditional_conditioning,\n\u001b[1;32m    111\u001b[0m                                             )\n\u001b[1;32m    112\u001b[0m \u001b[39mreturn\u001b[39;00m samples, intermediates\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.9/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/mnt/data1/bardella_data/gitRepos/Thesis/ldm_porting/models/diffusion/plms.py:152\u001b[0m, in \u001b[0;36mPLMSSampler.plms_sampling\u001b[0;34m(self, cond, shape, x_T, ddim_use_original_steps, callback, timesteps, quantize_denoised, mask, x0, img_callback, log_every_t, temperature, noise_dropout, score_corrector, corrector_kwargs, unconditional_guidance_scale, unconditional_conditioning)\u001b[0m\n\u001b[1;32m    149\u001b[0m     img_orig \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mq_sample(x0, ts)  \u001b[39m# TODO: deterministic forward pass?\u001b[39;00m\n\u001b[1;32m    150\u001b[0m     img \u001b[39m=\u001b[39m img_orig \u001b[39m*\u001b[39m mask \u001b[39m+\u001b[39m (\u001b[39m1.\u001b[39m \u001b[39m-\u001b[39m mask) \u001b[39m*\u001b[39m img\n\u001b[0;32m--> 152\u001b[0m outs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mp_sample_plms(img, cond, ts, index\u001b[39m=\u001b[39;49mindex, use_original_steps\u001b[39m=\u001b[39;49mddim_use_original_steps,\n\u001b[1;32m    153\u001b[0m                           quantize_denoised\u001b[39m=\u001b[39;49mquantize_denoised, temperature\u001b[39m=\u001b[39;49mtemperature,\n\u001b[1;32m    154\u001b[0m                           noise_dropout\u001b[39m=\u001b[39;49mnoise_dropout, score_corrector\u001b[39m=\u001b[39;49mscore_corrector,\n\u001b[1;32m    155\u001b[0m                           corrector_kwargs\u001b[39m=\u001b[39;49mcorrector_kwargs,\n\u001b[1;32m    156\u001b[0m                           unconditional_guidance_scale\u001b[39m=\u001b[39;49munconditional_guidance_scale,\n\u001b[1;32m    157\u001b[0m                           unconditional_conditioning\u001b[39m=\u001b[39;49munconditional_conditioning,\n\u001b[1;32m    158\u001b[0m                           old_eps\u001b[39m=\u001b[39;49mold_eps, t_next\u001b[39m=\u001b[39;49mts_next)\n\u001b[1;32m    159\u001b[0m img, pred_x0, e_t \u001b[39m=\u001b[39m outs\n\u001b[1;32m    160\u001b[0m old_eps\u001b[39m.\u001b[39mappend(e_t)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.9/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/mnt/data1/bardella_data/gitRepos/Thesis/ldm_porting/models/diffusion/plms.py:234\u001b[0m, in \u001b[0;36mPLMSSampler.p_sample_plms\u001b[0;34m(self, x, c, t, index, repeat_noise, use_original_steps, quantize_denoised, temperature, noise_dropout, score_corrector, corrector_kwargs, unconditional_guidance_scale, unconditional_conditioning, old_eps, t_next)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(old_eps) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m    231\u001b[0m     \u001b[39m# 4nd order Pseudo Linear Multistep (Adams-Bashforth)\u001b[39;00m\n\u001b[1;32m    232\u001b[0m     e_t_prime \u001b[39m=\u001b[39m (\u001b[39m55\u001b[39m \u001b[39m*\u001b[39m e_t \u001b[39m-\u001b[39m \u001b[39m59\u001b[39m \u001b[39m*\u001b[39m old_eps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m37\u001b[39m \u001b[39m*\u001b[39m old_eps[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m] \u001b[39m-\u001b[39m \u001b[39m9\u001b[39m \u001b[39m*\u001b[39m old_eps[\u001b[39m-\u001b[39m\u001b[39m3\u001b[39m]) \u001b[39m/\u001b[39m \u001b[39m24\u001b[39m\n\u001b[0;32m--> 234\u001b[0m x_prev, pred_x0 \u001b[39m=\u001b[39m get_x_prev_and_pred_x0(e_t_prime, index)\n\u001b[1;32m    236\u001b[0m \u001b[39mreturn\u001b[39;00m x_prev, pred_x0, e_t\n",
      "File \u001b[0;32m/mnt/data1/bardella_data/gitRepos/Thesis/ldm_porting/models/diffusion/plms.py:201\u001b[0m, in \u001b[0;36mPLMSSampler.p_sample_plms.<locals>.get_x_prev_and_pred_x0\u001b[0;34m(e_t, index)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_x_prev_and_pred_x0\u001b[39m(e_t, index):\n\u001b[1;32m    200\u001b[0m     \u001b[39m# select parameters corresponding to the currently considered timestep\u001b[39;00m\n\u001b[0;32m--> 201\u001b[0m     a_t \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mfull((b, \u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m), alphas[index], device\u001b[39m=\u001b[39;49mdevice)\n\u001b[1;32m    202\u001b[0m     a_prev \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfull((b, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m), alphas_prev[index], device\u001b[39m=\u001b[39mdevice)\n\u001b[1;32m    203\u001b[0m     sigma_t \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfull((b, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m), sigmas[index], device\u001b[39m=\u001b[39mdevice)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# classes = [0,1,2,3,4,5,6,7,8]   # define classes to be sampled here\n",
    "classes = [7, 8]   # Choose the classes that we want the model sample from\n",
    "\n",
    "# As said by the official TF FID repo we should generate at least 10000 sample \n",
    "# in order to have a FID which is not sub-optimal \n",
    "\n",
    "n_samples_per_class = 10_000 \n",
    "\n",
    "max_batch_size = 15\n",
    "FIDs = {}\n",
    "if os.path.exists(ROOT_PATH + \"/FIDs.npy\"):\n",
    "    with open(ROOT_PATH + \"/FIDs.npy\", \"rb\") as fin:\n",
    "        FIDs = np.load(fin, allow_pickle=True).item()\n",
    "\n",
    "whenFID = [1000 * i for i in range(1, 11)]\n",
    "\n",
    "unconditional_class = 8\n",
    "\n",
    "# ddim_steps = [20, 50, 200, 500, 1000]\n",
    "ddim_steps = [75]\n",
    "ddim_eta = 0\n",
    "scale = 2  # for unconditional guidance\n",
    "\n",
    "for ddim_step in ddim_steps:\n",
    "    for cls in classes:\n",
    "\n",
    "        # Create the folder where to save the sample\n",
    "        sample_already_created = 0\n",
    "        save_folder = sample_folder + f\"/{sampler_type}/{ddim_step}/{mapping_r[cls]}\"\n",
    "        if not os.path.exists(save_folder):\n",
    "            os.makedirs(save_folder)\n",
    "        else:\n",
    "            sample_already_created = len([file for file in os.listdir(save_folder) if os.path.isfile(os.path.join(save_folder, file))])\n",
    "\n",
    "        image_counter = sample_already_created\n",
    "        with torch.no_grad():\n",
    "            with model.ema_scope():\n",
    "                \n",
    "                n_samples_per_class -= sample_already_created\n",
    "                print(f\"\\nRendering {n_samples_per_class} examples of class '{mapping_r[cls]}' in {ddim_step} steps and using s={scale:.2f}.\")\n",
    "                if n_samples_per_class > max_batch_size:\n",
    "                    sub_batches = [max_batch_size] * (n_samples_per_class//max_batch_size)\n",
    "                    \n",
    "                    if n_samples_per_class % max_batch_size != 0 :\n",
    "                        sub_batches.append(n_samples_per_class % max_batch_size)\n",
    "\n",
    "                else:\n",
    "                    sub_batches = [n_samples_per_class]\n",
    "\n",
    "                for idx_sub_batch, sub_batch_size in enumerate(sub_batches):\n",
    "                    # Un-conditional class for free classifier sampling\n",
    "                    uc = model.get_learned_conditioning({model.cond_stage_key: torch.tensor(sub_batch_size*[unconditional_class]).to(model.device)}) if scale != 1 else None\n",
    "                    \n",
    "                    #Conditional class\n",
    "                    xc = torch.tensor(sub_batch_size*[cls])\n",
    "                    c = model.get_learned_conditioning({model.cond_stage_key: xc.to(model.device)})\n",
    "                    \n",
    "                    samples_ddim, _ = sampler.sample(S=ddim_step,\n",
    "                                                    conditioning=c,\n",
    "                                                    batch_size=sub_batch_size,\n",
    "                                                    shape=[4, 32, 32],\n",
    "                                                    verbose=False,\n",
    "                                                    unconditional_guidance_scale=scale,\n",
    "                                                    unconditional_conditioning=uc, \n",
    "                                                    eta=ddim_eta)\n",
    "\n",
    "                    x_samples_ddim = model.decode_first_stage(samples_ddim)\n",
    "                    x_samples_ddim = torch.clamp((x_samples_ddim+1.0)/2.0, min=0.0, max=1.0).cpu()\n",
    "\n",
    "                    # Save the just generated images and delete\n",
    "                    for idx_img, images in enumerate(torch.chunk(x_samples_ddim, chunks = sub_batch_size, dim = 0)):\n",
    "                        \n",
    "                        final_image = 255. * rearrange(torch.squeeze(images, dim=0), 'c h w -> h w c').numpy()\n",
    "                        final_image = Image.fromarray(final_image.astype(np.uint8))\n",
    "                        image_number = sample_already_created + idx_img + idx_sub_batch * sub_batch_size\n",
    "                        final_image.save(save_folder+ f\"/image_{image_number}.png\")\n",
    "                    \n",
    "                        image_counter += 1\n",
    "\n",
    "                        if image_counter in whenFID:\n",
    "                            FIDs[f\"{sampler_type}_{image_counter}_{mapping_r[cls]}\"] = computeFidPytorch(\n",
    "                                                                                        truth_dataset=dataset_subdivided_dir + f\"/{mapping_r[cls]}\", \n",
    "                                                                                        generated_dataset=save_folder, \n",
    "                                                                                        device=\"cuda:1\"\n",
    "                                                                                        )\n",
    "                            with open(\"FIDs.npy\", \"wb\") as fout:\n",
    "                                np.save(fout, FIDs, allow_pickle=True)\n",
    "                        \n",
    "\n",
    "                    # Delete the sampling tensor to reuse GPU memory istantly\n",
    "                    del x_samples_ddim\n",
    "                    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our samples against the all dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 396/396 [05:50<00:00,  1.13it/s]\n",
      "100%|██████████| 400/400 [00:47<00:00,  8.44it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "105.22606"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = \"arancione\"\n",
    "computeFidPytorch(\"/mnt/data1/bardella_data/gitRepos/Thesis/Datasets/wikiart_no_subdivision\",\n",
    "                  f\"/mnt/data1/bardella_data/gitRepos/Thesis/ldm_porting/sample/ldm/wikiart/PLMS/75/{label}\",\n",
    "                  device=\"cuda:1\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FID COMPUTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow inplementation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this cell we need to have tensorflow Version 1.1 installed with python 3.7\n",
    "\n",
    "CLI command:\n",
    "\n",
    "conda install -c anaconda tensorflow-gpu=1.15 python=3.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "# from pprint import pprint\n",
    "# import numpy\n",
    "\n",
    "# labels = [\"arancione\", \"bianco\", \"blu\", \"giallo\", \"nero\", \"rosso\", \"verde\", \"viola\"]\n",
    "# truth_label = \"arancione\"\n",
    "# generated_dataset = f\"/mnt/data1/bardella_data/gitRepos/Thesis/ldm_porting/sample/ldm/wikiart/200/{truth_label}\"\n",
    "\n",
    "# device =  \"0\"\n",
    "\n",
    "# FIDs = {}\n",
    "# for label in labels:\n",
    "\n",
    "#     truth_dataset = f\"/mnt/data1/bardella_data/gitRepos/Thesis/Datasets/wikiart_subdivided/{label}\"\n",
    "\n",
    "#     output = subprocess.run(['/home/bardella/.conda/envs/thesis_tf/bin/python', \n",
    "#                             \"/mnt/data1/bardella_data/gitRepos/Thesis/ldm_porting/modules/fid.py\", \n",
    "#                             truth_dataset,\n",
    "#                             generated_dataset,\n",
    "#                             \"--gpu\",\n",
    "#                             \"0\",\n",
    "#                             ], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
    "\n",
    "#     FIDs[\"_Vs_\".join((label, truth_label))] = numpy.float32(output.split(\" \")[-1][:-1])\n",
    "\n",
    "# pprint(FIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Paths\n",
    "# import modules.fid as fid\n",
    "# import glob\n",
    "# from skimage import imread\n",
    "# import tensorflow as tf\n",
    "\n",
    "# image_path = '/tmp/images' # set path to some generated images\n",
    "# stats_path = 'fid_stats.npz' # training set statistics\n",
    "# inception_path = fid.check_or_download_inception(None) # download inception network\n",
    "\n",
    "# # loads all images into memory (this might require a lot of RAM!)\n",
    "# image_list = glob.glob(os.path.join(image_path, '*.jpg'))\n",
    "# images = np.array([imread(str(fn)).astype(np.float32) for fn in files])\n",
    "\n",
    "# # load precalculated training set statistics\n",
    "# f = np.load(stats_path)\n",
    "# mu_real, sigma_real = f['mu'][:], f['sigma'][:]\n",
    "# f.close()\n",
    "\n",
    "# fid.create_inception_graph(inception_path)  # load the graph into the current TF graph\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "#     mu_gen, sigma_gen = fid.calculate_activation_statistics(images, sess, batch_size=100)\n",
    "\n",
    "# fid_value = fid.calculate_frechet_distance(mu_gen, sigma_gen, mu_real, sigma_real)\n",
    "# print(\"FID: %s\" % fid_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
